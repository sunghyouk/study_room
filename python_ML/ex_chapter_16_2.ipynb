{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### 16.3.2 두 번째 프로젝트: 텐서플로로 글자 단위 언어 모델 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-04-28 17:39:01--  https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch16/1268-0.txt\r\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\r\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\r\n",
      "HTTP request sent, awaiting response... 200 OK\r\n",
      "Length: 1171600 (1.1M) [text/plain]\r\n",
      "Saving to: ‘1268-0.txt.1’\r\n",
      "\r\n",
      "1268-0.txt.1        100%[===================>]   1.12M  --.-KB/s    in 0.06s   \r\n",
      "\r\n",
      "2022-04-28 17:39:01 (18.0 MB/s) - ‘1268-0.txt.1’ saved [1171600/1171600]\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# 데이터 다운로드\n",
    "!wget https://raw.githubusercontent.com/rickiepark/python-machine-learning-book-3rd-edition/master/ch16/1268-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 길이:  1112350\n",
      "고유한 문자:  80\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 읽어 들이기\n",
    "import numpy as np\n",
    "\n",
    "with open('1268-0.txt', 'r', encoding='UTF8') as fp:\n",
    "    text=fp.read()\n",
    "start_indx = text.find('THE MYSTERIOUS ISLAND')\n",
    "end_indx = text.find('End of the Project Gutenberg')\n",
    "text = text[start_indx:end_indx]\n",
    "char_set = set(text)\n",
    "print('전체 길이: ', len(text))\n",
    "print('고유한 문자: ', len(char_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "인코딩된 텍스트 크기:  (1112350,)\n"
     ]
    }
   ],
   "source": [
    "# 문자를 정수로 정수를 문자로 매핑\n",
    "chars_sorted = sorted(char_set)\n",
    "char2int = {ch:i for i, ch in enumerate(chars_sorted)}\n",
    "char_array = np.array(chars_sorted)\n",
    "\n",
    "text_encoded = np.array(\n",
    "    [char2int[ch] for ch in text],\n",
    "    dtype=np.int32)\n",
    "print('인코딩된 텍스트 크기: ', text_encoded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE MYSTERIOUS     --> 인코딩 -->  [44 32 29  1 37 48 43 44 29 42 33 39 45 43  1]\n",
      "[33 43 36 25 38 28]    --> 디코딩 -->  ISLAND\n"
     ]
    }
   ],
   "source": [
    "print(text[:15], '   --> 인코딩 --> ', text_encoded[:15])\n",
    "print(text_encoded[15:21], '   --> 디코딩 --> ', ''.join(char_array[text_encoded[15:21]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44 -> T\n",
      "32 -> H\n",
      "29 -> E\n",
      "1 ->  \n",
      "37 -> M\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 17:39:05.864320: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 인코딩된 텍스트 데이터로 텐서플로 데이터셋 만들기\n",
    "import tensorflow as tf\n",
    "ds_text_encoded = tf.data.Dataset.from_tensor_slices(text_encoded)\n",
    "for ex in ds_text_encoded.take(5):\n",
    "    print('{} -> {}'.format(ex.numpy(), char_array[ex.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# batch() - 41개의 문자로 구성된 텍스트 조각을 만들기\n",
    "# x - [0:40], y - [1:40]\n",
    "seq_length = 40\n",
    "chunk_size = seq_length + 1\n",
    "ds_chunks = ds_text_encoded.batch(chunk_size, drop_remainder=True)\n",
    "\n",
    "# x & y 나누기 위한 함수 정의\n",
    "def split_input_target(chunk):\n",
    "    input_seq = chunk[:-1]\n",
    "    target_seq = chunk[1:]\n",
    "    return input_seq, target_seq\n",
    "ds_sequences = ds_chunks.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "입력 (x):  'THE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced b'\n",
      "타깃 (y):  'HE MYSTERIOUS ISLAND ***\\n\\n\\n\\n\\nProduced by'\n",
      "\n",
      "입력 (x):  ' Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n'\n",
      "타깃 (y):  'Anthony Matonak, and Trevor Carlson\\n\\n\\n\\n\\n'\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-28 17:39:05.954364: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    }
   ],
   "source": [
    "for example in ds_sequences.take(2):\n",
    "    print('입력 (x): ', repr(''.join(char_array[example[0].numpy()])))\n",
    "    print('타깃 (y): ', repr(''.join(char_array[example[1].numpy()])))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 미니배치로 나누기\n",
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "ds = ds_sequences.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# 문자 수준의 RNN 모델 만들기\n",
    "def build_model(vocab_size, embedding_dim, rnn_units):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "        tf.keras.layers.LSTM(rnn_units, return_sequences=True),\n",
    "        tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 256)         20480     \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 512)         1574912   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 80)          41040     \n",
      "=================================================================\n",
      "Total params: 1,636,432\n",
      "Trainable params: 1,636,432\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 매개변수 설정\n",
    "charset_size = len(char_array)\n",
    "embedding_dim = 256\n",
    "rnn_units = 512\n",
    "tf.random.set_seed(1)\n",
    "model = build_model(\n",
    "    vocab_size=charset_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    rnn_units=rnn_units)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "424/424 [==============================] - 156s 362ms/step - loss: 2.7261\n",
      "Epoch 2/20\n",
      "424/424 [==============================] - 160s 375ms/step - loss: 1.8141\n",
      "Epoch 3/20\n",
      "424/424 [==============================] - 199s 467ms/step - loss: 1.5797\n",
      "Epoch 4/20\n",
      "424/424 [==============================] - 160s 375ms/step - loss: 1.4471\n",
      "Epoch 5/20\n",
      "424/424 [==============================] - 160s 374ms/step - loss: 1.3690\n",
      "Epoch 6/20\n",
      "424/424 [==============================] - 159s 373ms/step - loss: 1.3115\n",
      "Epoch 7/20\n",
      "424/424 [==============================] - 146s 342ms/step - loss: 1.2704\n",
      "Epoch 8/20\n",
      "424/424 [==============================] - 141s 332ms/step - loss: 1.2347\n",
      "Epoch 9/20\n",
      "424/424 [==============================] - 144s 337ms/step - loss: 1.2086\n",
      "Epoch 10/20\n",
      "424/424 [==============================] - 147s 343ms/step - loss: 1.1860\n",
      "Epoch 11/20\n",
      "424/424 [==============================] - 148s 347ms/step - loss: 1.1649\n",
      "Epoch 12/20\n",
      "424/424 [==============================] - 143s 335ms/step - loss: 1.1462\n",
      "Epoch 13/20\n",
      "424/424 [==============================] - 142s 333ms/step - loss: 1.1330\n",
      "Epoch 14/20\n",
      "424/424 [==============================] - 141s 331ms/step - loss: 1.1157\n",
      "Epoch 15/20\n",
      "424/424 [==============================] - 143s 337ms/step - loss: 1.1008\n",
      "Epoch 16/20\n",
      "424/424 [==============================] - 142s 332ms/step - loss: 1.0882\n",
      "Epoch 17/20\n",
      "424/424 [==============================] - 148s 347ms/step - loss: 1.0727\n",
      "Epoch 18/20\n",
      "424/424 [==============================] - 144s 337ms/step - loss: 1.0604\n",
      "Epoch 19/20\n",
      "424/424 [==============================] - 142s 334ms/step - loss: 1.0459\n",
      "Epoch 20/20\n",
      "424/424 [==============================] - 142s 333ms/step - loss: 1.0335\n"
     ]
    },
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x7f8cfbb82c10>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 컴파일 - 훈련\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                  from_logits=True\n",
    "                  ))\n",
    "model.fit(ds, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "확률:  [0.33333334 0.33333334 0.33333334]\n",
      "array([[0, 0, 1, 2, 0, 0, 0, 0, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "# 평가 단계: 새로운 텍스트 생성\n",
    "\n",
    "# Example1) categorical로 logit의 softmax 값에 따라 어느 범주로 할당될 지 확률로 배정\n",
    "tf.random.set_seed(1)\n",
    "logits = [[1.0, 1.0, 1.0]]\n",
    "print('확률: ', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(\n",
    "    logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "확률:  [0.10650698 0.10650698 0.78698605]\n",
      "array([[2, 0, 2, 2, 2, 0, 1, 2, 2, 0]])\n"
     ]
    }
   ],
   "source": [
    "# Example2) categorical로 logit의 softmax 값에 따라 어느 범주로 할당될 지 확률로 배정\n",
    "tf.random.set_seed(1)\n",
    "logits = [[1.0, 1.0, 3.0]]\n",
    "print('확률: ', tf.math.softmax(logits).numpy()[0])\n",
    "\n",
    "samples = tf.random.categorical(\n",
    "    logits=logits, num_samples=10)\n",
    "tf.print(samples.numpy())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def sample(model, starting_str,\n",
    "           len_generated_text=500,\n",
    "           max_input_length=40,\n",
    "           scale_factor=1.0):\n",
    "    encoded_input = [char2int[s] for s in starting_str]\n",
    "    encoded_input = tf.reshape(encoded_input, (1, -1))\n",
    "\n",
    "    generated_str = starting_str\n",
    "\n",
    "    model.reset_states()\n",
    "    for i in range(len_generated_text):\n",
    "        logits = model(encoded_input)\n",
    "        logits = tf.squeeze(logits, 0)\n",
    "\n",
    "        scaled_logits = logits * scale_factor\n",
    "        new_char_indx = tf.random.categorical(\n",
    "            scaled_logits, num_samples=1)\n",
    "\n",
    "        new_char_indx = tf.squeeze(new_char_indx)[-1].numpy()\n",
    "\n",
    "        generated_str += str(char_array[new_char_indx])\n",
    "\n",
    "        new_char_indx = tf.expand_dims([new_char_indx], 0)\n",
    "        encoded_input = tf.concat([encoded_input, new_char_indx], axis=1)\n",
    "        encoded_input = encoded_input[:, -max_input_length:]\n",
    "\n",
    "    return generated_str"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The island must be dead.\n",
      "\n",
      "When the worked over by felt as a great moment. They had no\n",
      "contact in shember in the dark possible stood off in one which back possession directed by\n",
      "showling volcanic\n",
      "elover, the sailor’s fleside! Pencroft had not think that their interrupted very preoccumution. The highest vessel, destroy again, and\n",
      "Pencroft, wardled withwemp that\n",
      "an hour to utter they did not possibe\n",
      "that they could not result the entrance, which did not washing of\n",
      "his great granite, heaving\n",
      "warm, and\n",
      "this si\n"
     ]
    }
   ],
   "source": [
    "tf.random.set_seed(1)\n",
    "print(sample(model, starting_str='The island'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "dc1b947dce198ff7f2d2cb152b2cbb61132fce4429fa808fd5b89ac4d7df39fa"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('tf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}