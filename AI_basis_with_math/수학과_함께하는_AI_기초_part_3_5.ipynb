{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## 05. 학습하기\n",
    "### 5-2 다층 신경망\n",
    "#### 5-2-3 퍼셉트론 간의 신호를 전달하는 순전파"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "def Sigmoid(z):\r\n",
    "    return 1/(1+np.exp(-z))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "# 편미분 함수 정의하기 -- 책에 별도의 설명이 없음\r\n",
    "def numerical_derivative(f, x):\r\n",
    "    delta_x = 1e-4 # 0.0001\r\n",
    "    grad = np.zeros_like(x)\r\n",
    "    \r\n",
    "    it = np.nditer(x, flags=['multi_index'], op_flags=['readwrite'])\r\n",
    "    \r\n",
    "    while not it.finished:\r\n",
    "        idx = it.multi_index        \r\n",
    "        tmp_val = x[idx]\r\n",
    "        x[idx] = float(tmp_val) + delta_x\r\n",
    "        fx1 = f(x) # f(x+delta_x)\r\n",
    "        \r\n",
    "        x[idx] = tmp_val - delta_x \r\n",
    "        fx2 = f(x) # f(x-delta_x)\r\n",
    "        grad[idx] = (fx1 - fx2) / (2*delta_x)\r\n",
    "        \r\n",
    "        x[idx] = tmp_val \r\n",
    "        it.iternext()   \r\n",
    "        \r\n",
    "    return grad"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "class my_NN01:\r\n",
    "    # 클래스 생성자를 선언\r\n",
    "    def __init__(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\r\n",
    "        self.input_nodes = input_nodes\r\n",
    "        self.hidden_nodes = hidden_nodes\r\n",
    "        self.output_nodes = output_nodes\r\n",
    "\r\n",
    "        # 은닉층의 파라미터 W1, B1을 초기화\r\n",
    "        self.W1 = np.random.rand(self.input_nodes, self.hidden_nodes)/np.sqrt(self.input_nodes/2) # 수렴값을 빠르게 찾기 위해서\r\n",
    "        self.B1 = np.random.rand(self.hidden_nodes)\r\n",
    "        \r\n",
    "        # 출력층의 파라미터 W2, B2를 초기화\r\n",
    "        self.W2 = np.random.rand(self.hidden_nodes, self.output_nodes)/np.sqrt(self.hidden_nodes/2)\r\n",
    "        self.B2 = np.random.rand(self.output_nodes)\r\n",
    "\r\n",
    "        # 학습률 learning rate 초기화\r\n",
    "        self.learning_rate = learning_rate\r\n",
    "\r\n",
    "    # 순전파\r\n",
    "    def feed_forward(self):\r\n",
    "        delta = 1e-7\r\n",
    "        A1 = np.dot(self.input_nodes, self.W1) + self.B1\r\n",
    "        Z1 = Sigmoid(A1)\r\n",
    "        A2 = np.dot(Z1, self.W2) + self.B2\r\n",
    "        y = Sigmoid(A2)\r\n",
    "        return -np.sum(self.target_data * np.log(y + delta) + (1-self.target_data) * np.log((1-y) + delta)) # 계산의 편의를 위해 순전파 출력 시 로그최대우도추정법 계산을 적용\r\n",
    "\r\n",
    "        # 5-2-4 파라미터를 결정하는 비용함수\r\n",
    "        # 로그최대우도 추정법의 비용함수로 작성\r\n",
    "    def cost(self):\r\n",
    "        delta = 1e-7\r\n",
    "        A1 = np.dot(self.input_data, self.W1) + self.B1\r\n",
    "        Z1 = Sigmoid(A1)\r\n",
    "        A2 = np.dot(Z1, self.W2) + self.B2\r\n",
    "        y = Sigmoid(A2)\r\n",
    "\r\n",
    "        # 로그최대우도추정법\r\n",
    "        cost_val = -np.sum(self.target_data * np.log(y + delta) + (1-self.target_data) * np.log((1-y) + delta))\r\n",
    "        return cost_val\r\n",
    "\r\n",
    "        # 5-2-5 경사하강법을 적용한 train 함수\r\n",
    "    def train(self, input_data, target_data):\r\n",
    "        self.input_data = input_data\r\n",
    "        self.target_data = target_data\r\n",
    "        f = lambda x: self.feed_forward()\r\n",
    "        self.W1 -= self.learning_rate * numerical_derivative(f, self.W1)\r\n",
    "        self.B1 -= self.learning_rate * numerical_derivative(f, self.B1)\r\n",
    "        self.W2 -= self.learning_rate * numerical_derivative(f, self.W2)\r\n",
    "        self.B2 -= self.learning_rate * numerical_derivative(f, self.B2)\r\n",
    "    \r\n",
    "        # 5-2-6 평가를 위한 예측 함수와 정확도 함수 정의하기\r\n",
    "    def predict(self, input_data):\r\n",
    "        A1 = np.dot(self.input_data, self.W1) + self.B1\r\n",
    "        Z1 = Sigmoid(A1)\r\n",
    "        A2 = np.dot(Z1, self.W2) + self.B2\r\n",
    "        y = Sigmoid(A2)\r\n",
    "        predicted_num = np.argmax(y)\r\n",
    "        return predicted_num\r\n",
    "\r\n",
    "    def accuracy(selt, test_data):\r\n",
    "        matched_list = []\r\n",
    "        not_matched_list = []\r\n",
    "\r\n",
    "        for index in range(len(test_data)):\r\n",
    "            label = int(test_data[index, 0])\r\n",
    "            data = (test_data[index, 1:]/255.0 *0.99) + 0.01\r\n",
    "            predicted_num = self.predict(np.array(data, ndmin = 2))\r\n",
    "            if label == predicted_num:\r\n",
    "                matched_list.append(index)\r\n",
    "            else:\r\n",
    "                not_matched_list.append(index)\r\n",
    "    \r\n",
    "        print('정확도: ', 100*(len(matched_list)/(len(test_data))), '%')\r\n",
    "        return matched_list, not_matched_list"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 5-3 모델 학습하기\n",
    "#### Step 1. 사용할 데이터 셋 분리하기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "import pandas as pd\r\n",
    "df_train = pd.read_csv('G:\\\\내 드라이브\\\\Colab Notebooks\\\\fashion-mnist_train.csv') # verify your data stored folder\r\n",
    "df_test = pd.read_csv('G:\\\\내 드라이브\\\\Colab Notebooks\\\\fashion-mnist_test.csv')\r\n",
    "\r\n",
    "data_train = np.array(df_train, dtype = np.float32)\r\n",
    "data_test = np.array(df_test, dtype=np.float32)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Step 2. 사용할 데이터 모델 만들기"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "my_model = my_NN01(784, 100, 10, 0.01)\r\n",
    "cost_val_list = []\r\n",
    "\r\n",
    "for step in range(len(data_train)):\r\n",
    "    input_data = ((data_train[step, 1:]/255.0) * 0.99) + 0.01\r\n",
    "    target_data = np.zeros(10) + 0.01\r\n",
    "    target_data[int(data_train[step, 0])] = 0.99\r\n",
    "    my_model.train(input_data, target_data)\r\n",
    "\r\n",
    "    if(step % 200 == 0):\r\n",
    "        print('단계: ', step, ', 비용 (손실) 값: ', my_model.cost())\r\n",
    "\r\n",
    "    cost_val_list.append(my_model.cost())"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "my_model.accuracy(data_test)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.7",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.7 64-bit"
  },
  "interpreter": {
   "hash": "6831775c7e8ac6118cb715c292c35aadaa899790dc73e59f961ed1a7ee347e6d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}