{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4. word2vec 속도 개선\n",
    "\n",
    "가장 큰 문제 - 말뭉치에 포함된 어휘 수가 많아지면 계산량도 커진다.  \n",
    "\n",
    "1) `Embedding` - 새로운 계층을 추가\n",
    "2) `negative sampling` - 새로운 손실함수를 도입\n",
    "\n",
    "`PTB dataset`을 가지고 학습을 수행\n",
    "\n",
    "## 4.1 word2vec 개선 1\n",
    "\n",
    "* 입력층의 원핫 표현과 가중치 행렬 $\\mathbf{W}_{in}$의 곱 계산 -> `Embedding`으로 해결\n",
    "* 은닉층과 가중치 행렬 $\\mathbf{W}_{out}$의 곱 및 softmax 계층의 계산 -> `negative sampling`으로 해결\n",
    "\n",
    "*Reference)*  \n",
    "ch03 디렉토리의 simple_cbow.py, simple_skip_gram.py는 3장의 개선 전 간단 구현  \n",
    "ch04 디렉토리의 cbow.py, skip_gram.py는 4장의 개선 후 구현  \n",
    "\n",
    "### 4.1.1 Embedding 계층\n",
    "\n",
    "단지 행렬의 특정 행을 추출하는 것 뿐이다.  \n",
    "행렬 곱 계산은 사실 필요가 없는 것  \n",
    "`embedding` 계층에 단어 임베딩 (분산 표현)을 저장  \n",
    "\n",
    "### 4.1.2 Embedding 계층 구현\n",
    "\n",
    "GOTO: common/layers.py  \n",
    "\n",
    "## 4.2 word2vec 개선 2\n",
    "\n",
    "### 4.2.1 은닉층 이후 계산의 문제점\n",
    "\n",
    "* 은닉층의 뉴런과 가중치 행렬의 곱\n",
    "* softmax 계층의 계산\n",
    "\n",
    "### 4.2.2 다중 분류에서 이진 분류로\n",
    "\n",
    "### 4.2.3 시그모이드 함수와 교차 엔트로피 오차\n",
    "\n",
    "다중 분류를 이진 분류로 근사하는 것: sigmoid with loss  \n",
    "loss는 cross entropy error 함수  \n",
    "\n",
    "### 4.2.4 다중 분류에서 이진 분류로 (구현)\n",
    "\n",
    "*Example* 보면 이해가 한 번에 됨\n",
    "\n",
    "### 4.2.5 네거티브 샘플링\n",
    "\n",
    "부정적 예에 대해서 sigmoid 계층의 출력을 0에 가깝게 만드는 것  \n",
    "적은 수의 부정적 예를 샘플링해 사용  \n",
    "긍정적 예와 샘플링된 부정적 예의 손실을 더한 값을 최종 손실로 함\n",
    "\n",
    "### 4.2.6 네거티브 샘플링의 샘플링 기법\n",
    "\n",
    "부정적 예를 어떻게 샘플링하느냐  \n",
    "말뭉치에서 자주 등장하는 단어를 많이 추출하고 드물게 등장하는 단어를 적게 추출 - 각 단어의 출현 회수를 구해 '확률분포'로 나타냄  \n",
    "\n",
    "`np.random.choice()` 함수 이용 - 무작위 샘플링 용도로 이용  \n",
    "`size` 인자: 샘플링을 size만큼 수행  \n",
    "`replcae=False` 인자: 샘플링 시 중복을 허용 안 함  \n",
    "`p`에 확률분포를 담은 리스트를 지정하면 확률분포대로 샘플링  \n",
    "\n",
    "\n",
    "*Reference)*  \n",
    "`np.power`: 출현 확률이 낮은 단어를 버리지 않기 위해 약간의 제곱 (예: 0.75)을 해서 확률을 높여줌  \n",
    "NOTE: ch04/negative_sampling_layer.py의 `UnigramSampler` 클래스 참고  \n",
    "\n",
    "### 4.2.7 네거티브 샘플링 구현\n",
    "\n",
    "GOTO: ch04/negative_sampling_layer.py의 `NegativeSamplingLoss` 클래스  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
